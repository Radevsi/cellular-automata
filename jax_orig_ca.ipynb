{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wcqKm9S9vka",
    "outputId": "41542719-c730-4808-87df-3c32ceac44f4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "\n",
    "import io\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import jit, grad, lax\n",
    "import optax\n",
    "import haiku as hk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from IPython.display import Image, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9bS9O21W99Pb"
   },
   "outputs": [],
   "source": [
    "TARGET_SIZE = 40\n",
    "\n",
    "def load_image(url, max_size=TARGET_SIZE):\n",
    "  r = requests.get(url)\n",
    "  img = PIL.Image.open(io.BytesIO(r.content))\n",
    "  img.thumbnail((max_size, max_size), PIL.Image.Resampling.LANCZOS)\n",
    "  img = jnp.float32(img) / 255.0\n",
    "\n",
    "  # premultiply RGB by Alpha\n",
    "  img.at[..., :3].set(img[..., 3:])\n",
    "  # img[..., :3] *= img[..., 3:]\n",
    "  return img\n",
    "\n",
    "def load_emoji(emoji):\n",
    "  # code = hex(ord(emoji)).a.lower()\n",
    "  code = hex(ord(emoji))[2:].lower()\n",
    "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
    "  return load_image(url)\n",
    "\n",
    "def np2pil(a):\n",
    "  if a.dtype in [jnp.float32, jnp.float64]:\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None):\n",
    "  a = jnp.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=95)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = jnp.asarray(a)\n",
    "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "  display(Image(data=imencode(a, fmt)))\n",
    "\n",
    "def to_rgba(x):\n",
    "  \"This function used outside model, using original shaping conventions\"\n",
    "  return x[..., :4] # may need to change for JAX's immutability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tcJzkNzp99S1"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "TARGET_PADDING = 16\n",
    "\n",
    "CHANNEL_N = 16\n",
    "TARGET_PADDING = 16\n",
    "BATCH_SIZE = 8\n",
    "CELL_FIRE_RATE = 0.5\n",
    "\n",
    "TARGET_EMOJI = \"ðŸ›©\"\n",
    "\n",
    "# Load target image\n",
    "target_img = load_emoji(TARGET_EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0),\n",
       " StreamExecutorGpuDevice(id=1, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "id": "L8kPhPK2BPMs",
    "outputId": "8f7883bf-d62e-4da2-9507-04dca3f0ad7c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(target_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "atW0TcTKcmWe",
    "outputId": "99aceef8-2e79-4e97-dea1-ced521a3ff9c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEgAAABICAYAAABV7bNHAAAAMUlEQVR4nO3OMQEAAAgDoPUvrSF2eAgJSAAAAAAAAAAAAAB+mOsAAAAAAAAAAAAAUFs7kAEAueYivgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make seed image\n",
    "p = TARGET_PADDING\n",
    "pad_target = jnp.pad(target_img, ((p, p), (p, p), (0, 0)))\n",
    "h, w = pad_target.shape[:2]\n",
    "seed = jnp.zeros((h, w, CHANNEL_N), jnp.float32)\n",
    "seed = seed.at[h//2, w//2, 3:].set(1)\n",
    "x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0) # batch it up\n",
    "imshow(seed[..., :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "<class 'haiku._src.transform.Transformed'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "f() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(f))\n\u001b[1;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/haiku/_src/transform.py:128\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    122\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    123\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the functions you are transforming use the same names you must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m out, state \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    130\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen use `hk.transform_with_state`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/haiku/_src/transform.py:357\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(params\u001b[38;5;241m=\u001b[39mparams, state\u001b[38;5;241m=\u001b[39mstate, rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    356\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: f() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "def f(a, b):\n",
    "    return a + b\n",
    "print(type(f))\n",
    "f = hk.transform(f)\n",
    "print(type(f))\n",
    "params = f.init(None, 1, 2)\n",
    "f.apply(params, None, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RJ039wKdFr7c"
   },
   "outputs": [],
   "source": [
    "# https://github.com/deepmind/dm-haiku#quickstart\n",
    "\n",
    "# Define CA model\n",
    "\n",
    "class CAModel(hk.Module):\n",
    "\n",
    "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE, name=None):\n",
    "    super().__init__(name=name) # follow documented convention by passing in `name`\n",
    "    self.channel_n = channel_n\n",
    "    self.fire_rate = fire_rate\n",
    "\n",
    "    self.model = hk.Sequential([\n",
    "        hk.Conv2D(output_channels=128, kernel_shape=1),\n",
    "        jax.nn.relu,\n",
    "        # initalize the below weights to zero\n",
    "        hk.Conv2D(output_channels=CHANNEL_N, kernel_shape=1),\n",
    "        # no activation function\n",
    "    ])\n",
    "\n",
    "  def perceive(self, x,):\n",
    "    identify = jnp.float32([0, 1, 0])\n",
    "    identify = jnp.outer(identify, identify)\n",
    "    dx = jnp.outer(jnp.float32([1, 2, 1]), \\\n",
    "                  jnp.float32([-1, 0, 1])) / 8.0  # Sobel filter\n",
    "    dy = dx.T\n",
    "    kernel = jnp.stack([identify, dx, dy], -1)[:, :, None, :]\n",
    "    kernel = jnp.repeat(kernel, 16, axis=2)\n",
    "\n",
    "    # kernel should be reshaped from [filter_height, filter_width, in_channels, channel_multiplier] to \n",
    "    # [filter_height, filter_width, 1, in_channels * channel_multiplier] per\n",
    "    # https://www.tensorflow.org/xla/operation_semantics\n",
    "    kernel_reshaped = kernel.reshape((3, 3, 1, 48))\n",
    "    # dimension_numbers specify shape of input, kernel, and output tensors\n",
    "    y = lax.conv_general_dilated(x0, kernel_reshaped, window_strides=(1, 1), padding=\"SAME\",  feature_group_count=16,\\\n",
    "                                dimension_numbers=('NHWC', 'HWIO', 'NHWC'))\n",
    "    return y\n",
    "\n",
    "  def __call__(self, x):\n",
    "\n",
    "    # Perceive neighbourhood\n",
    "    y = self.perceive(x)\n",
    "\n",
    "    # Pass through model\n",
    "    dx = self.model(y)\n",
    "    return x + dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "50WurAAdfOea"
   },
   "outputs": [],
   "source": [
    "def lift_model(x):\n",
    "  model = CAModel()\n",
    "  return model(x)\n",
    "\n",
    "# Make an object with `init` and `apply` methods\n",
    "ca_model = hk.transform(lift_model)\n",
    "\n",
    "key = hk.PRNGSequence(22)\n",
    "initial_params = ca_model.init(next(key), x0)\n",
    "# print(type(params), params)\n",
    "y = ca_model.apply(initial_params, None, x0)\n",
    "\n",
    "# print(x0.shape)\n",
    "# print(y.shape)\n",
    "# print(pad_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hShnuOLldhZr",
    "outputId": "7d13ed4c-c983-4176-a802-058abe7415bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 72, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72, 72, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pad_target.shape)\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bt7cOSdic8M2",
    "outputId": "e8ce95f4-82e0-4da4-a21f-982e60ec5e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 72, 4)\n",
      "(72, 72, 16) (8,)\n",
      "[0.8783978 0.8783978 0.8783978 0.8783978 0.8783978 0.8783978 0.8783978\n",
      " 0.8783978]\n"
     ]
    }
   ],
   "source": [
    "def loss_f(prediction, target):\n",
    "  return optax.l2_loss(to_rgba(prediction), target)\n",
    "\n",
    "def loss_f1(prediction, target):\n",
    "  return jnp.mean(jnp.square(to_rgba(prediction) - target), axis=[-2, -3, -1])\n",
    "\n",
    "loss = loss_f(seed, pad_target)\n",
    "print(loss.shape)\n",
    "\n",
    "xtest = jnp.ones((8, 72, 72, 4))\n",
    "loss1 = loss_f1(xtest, pad_target)\n",
    "print(seed.shape, loss1.shape)\n",
    "print(loss1)\n",
    "\n",
    "x = jnp.ones((72, 72, 4))\n",
    "xloss = loss_f(x, pad_target)\n",
    "\n",
    "# print(jnp.allclose(loss, loss1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "b3_hh4oc7Zd_"
   },
   "outputs": [],
   "source": [
    "# Training sequence (no class this time)\n",
    "\n",
    "def loss_f(prediction, target):\n",
    "  return jnp.mean(jnp.square(to_rgba(prediction) - target), axis=[-2, -3, -1]).mean()\n",
    "\n",
    "def update(x, model, model_params, optimizer, optimizer_state):\n",
    "  \"\"\"This is where the actual learning happens\"\"\"\n",
    "  grads = jax.grad(loss_f)(x, pad_target)\n",
    "  print(f'grads is: {type(grads)}\\\n",
    "    and optimizer state is {type(optimizer_state)}')\n",
    "  # print(f'grads: {grads}')\n",
    "  updates, optimizer_state = optimizer.update(grads, optimizer_state, model_params)\n",
    "  model_params = optax.apply_updates(model_params, updates)\n",
    "  return model_params, optimizer_state, \n",
    "\n",
    "def train_step(x, model, model_params, \\\n",
    "               optimizer, optimizer_state):\n",
    "  iter_n = np.random.randint(64, 97, dtype=np.int32)\n",
    "  for _ in range(iter_n):\n",
    "    x = model.apply(model_params, None, x)\n",
    "  \n",
    "  # Update model params\n",
    "  model_params, optimizer_state = update(x, model, model_params, \\\n",
    "                                         optimizer, optimizer_state)\n",
    "  \n",
    "def train(x0, model, model_params, \\\n",
    "          optimizer, optimizer_state, n_train_steps=1000+1):\n",
    "  \n",
    "  for i in range(n_train_steps):\n",
    "    x, loss = train_step(x0, model, model_params, \\\n",
    "                         optimizer, optimizer_state)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "      clear_output()\n",
    "\n",
    "      # visualize batch\n",
    "      # plot loss\n",
    "      # expot model (if desired)\n",
    "    print('\\r step: %d, log10(loss): %.3f'%(i, np.log10(loss)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Mq1rFw9c5rtE",
    "outputId": "8e4f2062-5443-4e74-b82c-a92832c95f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads is: <class 'jaxlib.xla_extension.ArrayImpl'>    and optimizer state is <class 'tuple'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-3\u001b[39m)\n\u001b[1;32m     15\u001b[0m optimizer_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(initial_params)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(x0, model, model_params, optimizer, optimizer_state, n_train_steps)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(x0, model, model_params, \\\n\u001b[1;32m     27\u001b[0m           optimizer, optimizer_state, n_train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_train_steps):\n\u001b[0;32m---> 30\u001b[0m     x, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m       clear_output()\n",
      "Cell \u001b[0;32mIn[34], line 23\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x, model, model_params, optimizer, optimizer_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m   x \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mapply(model_params, \u001b[38;5;28;01mNone\u001b[39;00m, x)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Update model params\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m model_params, optimizer_state \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(x, model, model_params, optimizer, optimizer_state)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrads is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(grads)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m  and optimizer state is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(optimizer_state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(f'grads: {grads}')\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m updates, optimizer_state \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(model_params, updates)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_params, optimizer_state,\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/optax/_src/combine.py:54\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params)\u001b[0m\n\u001b[1;32m     52\u001b[0m new_state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 54\u001b[0m   updates, new_s \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mappend(new_s)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updates, \u001b[38;5;28mtuple\u001b[39m(new_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/optax/_src/transform.py:342\u001b[0m, in \u001b[0;36mscale_by_adam.<locals>.update_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fn\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    341\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m params\n\u001b[0;32m--> 342\u001b[0m   mu \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_moment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m   nu \u001b[38;5;241m=\u001b[39m update_moment_per_elem_norm(updates, state\u001b[38;5;241m.\u001b[39mnu, b2, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    344\u001b[0m   count_inc \u001b[38;5;241m=\u001b[39m numerics\u001b[38;5;241m.\u001b[39msafe_int32_increment(state\u001b[38;5;241m.\u001b[39mcount)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/optax/_src/transform.py:83\u001b[0m, in \u001b[0;36mupdate_moment\u001b[0;34m(updates, moments, decay, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_moment\u001b[39m(updates, moments, decay, order):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the exponential moving average of the `order`-th moment.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.11/site-packages/optax/_src/transform.py:84\u001b[0m, in \u001b[0;36mupdate_moment.<locals>.<lambda>\u001b[0;34m(g, t)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_moment\u001b[39m(updates, moments, decay, order):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the exponential moving average of the `order`-th moment.\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[0;32m---> 84\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m g, t: (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m decay) \u001b[38;5;241m*\u001b[39m (g \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m order) \u001b[38;5;241m+\u001b[39m \u001b[43mdecay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m, updates, moments)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "def lift_model(x):\n",
    "  model = CAModel()\n",
    "  return model(x)\n",
    "\n",
    "# Make an object with `init` and `apply` methods\n",
    "ca_model = hk.transform(lift_model)\n",
    "\n",
    "key = hk.PRNGSequence(22)\n",
    "initial_params = ca_model.init(next(key), x0)\n",
    "# print(type(params), params)\n",
    "# y = ca_model.apply(initial_params, None, x0)\n",
    "\n",
    "# Make optimizer\n",
    "optimizer = optax.adam(learning_rate=2e-3)\n",
    "optimizer_state = optimizer.init(initial_params)\n",
    "\n",
    "train(x0, ca_model, initial_params, \\\n",
    "      optimizer, optimizer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMsrlQbI4XRj",
    "outputId": "6a1ff168-956f-447d-9222-1074a22398e2"
   },
   "outputs": [],
   "source": [
    "arr = jnp.array([1,2,3])\n",
    "print(type(arr))\n",
    "arr[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "YJb01sLPp0fb",
    "outputId": "ef78dc84-c86b-48fd-d42c-c1f66e7f2a5e"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define the neural network as a pure function\n",
    "def neural_network(params, inputs):\n",
    "    layer1_weights = params['layer1_weights']\n",
    "    layer1_bias = params['layer1_bias']\n",
    "    layer2_weights = params['layer2_weights']\n",
    "    layer2_bias = params['layer2_bias']\n",
    "    \n",
    "    hidden = jax.nn.relu(jnp.dot(inputs, layer1_weights) + layer1_bias)\n",
    "    output = jnp.dot(hidden, layer2_weights) + layer2_bias\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Define the loss function as a pure function\n",
    "def loss(params, batch):\n",
    "    inputs, targets = batch\n",
    "    predictions = neural_network(params, inputs)\n",
    "    return jnp.mean((predictions - targets) ** 2)\n",
    "\n",
    "# Define the update function as a pure function\n",
    "def update(params, batch, opt_state):\n",
    "    grads = jax.grad(loss)(params, batch)\n",
    "    updates, new_opt_state = opt_update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state\n",
    "\n",
    "# Initialize the network parameters and optimizer\n",
    "params = jax.random.normal(jax.random.PRNGKey(0), (784, 10))\n",
    "opt_init, opt_update = optax.adam(1e-3)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "# Define the training loop\n",
    "@jax.jit\n",
    "def train_step(params, batch, opt_state):\n",
    "    # Compute the gradients and updated optimizer state\n",
    "    params, new_opt_state = update(params, batch, opt_state)\n",
    "    \n",
    "    # Compute the loss on this batch\n",
    "    loss_value = loss(params, batch)\n",
    "    \n",
    "    return params, new_opt_state, loss_value\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(5):\n",
    "    for i, batch in enumerate(data_batches):\n",
    "        # Take a training step on this batch\n",
    "        params, opt_state, loss_value = train_step(params, batch, opt_state)\n",
    "        \n",
    "        # Print the loss every 100 steps\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, step {i}, loss {loss_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_O-97l6p06o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
