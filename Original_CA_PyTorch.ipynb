{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1RN1Tc1aEcsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e4dbd1-e3ab-4d73-cd06-16843def4a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Notebook dependencies\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device is {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "\n",
        "TARGET_SIZE = 40\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  img = np.float32(img) / 255.0\n",
        "\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  return load_image(url)\n",
        "\n",
        "def to_rgba(x):\n",
        "  \"This function used outside model, using original shaping conventions\"\n",
        "  return x[..., :4]\n",
        "\n",
        "def get_living_mask(x):\n",
        "  \"This function used within model with PyTorch shaping conventions\"\n",
        "  alpha = x[:, 3:4, :, :]\n",
        "  return F.max_pool2d(alpha, kernel_size=3, stride=1, padding=1) > 0.1\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.title('Loss history (log10)')\n",
        "  plt.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "Kyud_-WxJwbN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "\n",
        "CHANNEL_N = 16\n",
        "TARGET_PADDING = 16\n",
        "BATCH_SIZE = 8\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "TARGET_EMOJI = \"ðŸ›©\"\n",
        "\n",
        "# Load target image\n",
        "target_img = load_emoji(TARGET_EMOJI)"
      ],
      "metadata": {
        "id": "1tsyf9fsGIbF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(target_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "ZAKqbC39Jvmw",
        "outputId": "feaa8203-127e-4bae-eff8-7cb7142d0cbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "\n",
        "class CAModel(nn.Module):\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=self.channel_n*3, out_channels=128, kernel_size=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=128, out_channels=self.channel_n, kernel_size=1)\n",
        "    ).to(device)\n",
        "\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    \"\"\"Pytorch does convolutions differently. Reshape accordingly\n",
        "      input is (batch, in_channels, H, W)\n",
        "      kernel is (filter_height, filter_width, in_channels, channel_multiplier)\n",
        "      but should be (out_channels, in_channels / groups, H, W)\"\"\"\n",
        "    identify = torch.as_tensor([0, 1, 0], dtype=torch.float32)\n",
        "    identify = torch.outer(identify, identify)\n",
        "    dx = torch.as_tensor(np.outer([1, 2, 1], [-1, 0, 1]) / 8.0, dtype=torch.float32) # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = torch.cos(torch.tensor(angle)), torch.sin(torch.tensor(angle))\n",
        "    kernel = torch.stack((identify, c*dx-s*dy, s*dx+c*dy)).to(device)\n",
        "    kernel = torch.repeat_interleave(kernel, self.channel_n, dim=0).view(self.channel_n*3, 1, 3, 3)\n",
        "    return F.conv2d(x, kernel, padding='same', groups=self.channel_n)\n",
        "\n",
        "  def forward(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    x = torch.permute(x, (0, 3, 1, 2))\n",
        "    # x = x.view(0, 3, 1, 2)\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle) # y should be on device\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = torch.rand(x.shape, dtype=torch.float32)[:, :, :, :1] <= fire_rate\n",
        "    x += dx * update_mask.to(device)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    result = x * life_mask\n",
        "    return torch.permute(result, (0, 2, 3, 1)) # send it back [batch_size, H, W, in_channels]\n",
        "\n",
        "CAModel().dmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Q54-JtRMkB",
        "outputId": "60db4616-b4d6-4be3-ad55-60954fbbc32c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make training sample\n",
        "\n",
        "p = TARGET_PADDING\n",
        "target_img_tensor = torch.tensor(target_img)\n",
        "pad_target = torch.nn.functional.pad(target_img_tensor, (0, 0, p, p, p, p))\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = torch.zeros(h, w, CHANNEL_N, dtype=torch.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "print(f'seed shape is {seed.shape}')\n",
        "\n",
        "plt.imshow(seed[..., :4])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "p88u8q9EGIdv",
        "outputId": "a60e7dde-8040-4216-80db-410cc668d996"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed shape is torch.Size([72, 72, 16])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Sequence\n",
        "\n",
        "class Train:\n",
        "  def __init__(self, ca_model, target, lr=2e-3):\n",
        "    self.ca = ca_model\n",
        "    self.target = target\n",
        "    self.lr = lr\n",
        "    # Initialize optimizer = no learning rate scheduler for now\n",
        "    self.optim = torch.optim.Adam(self.ca.parameters(), lr=self.lr)\n",
        "    # Use library MSELoss\n",
        "    self.loss_f = nn.MSELoss()\n",
        "\n",
        "    # Log the training progress\n",
        "    self.loss_log = []\n",
        "\n",
        "  def train(self, n_steps=1000):\n",
        "    \"Just support Growing mode for now\"\n",
        "\n",
        "    for i in range(n_steps+1):\n",
        "      # Seed input each time (starting from a single seed pixel)\n",
        "      x0 = torch.repeat_interleave(seed[None, ...], BATCH_SIZE, dim=0).to(device)\n",
        "\n",
        "      # Run through a single training step of the model\n",
        "      loss = self._train_step(x0)\n",
        "      self.loss_log.append(loss)\n",
        "      print(f'loss log is {self.loss_log}')\n",
        "\n",
        "      # Printing\n",
        "      if i % 100 == 0:\n",
        "        # clear_output()\n",
        "\n",
        "        # visualize batch\n",
        "        # plot loss\n",
        "        plot_loss(self.loss_log)\n",
        "        # export model\n",
        "\n",
        "      print('\\r step: %d, log10(loss): %.3f'%(len(self.loss_log), np.log10(loss)), end='')\n",
        "\n",
        "  def _train_step(self, x):\n",
        "    \"\"\"Perform the update step some random number of times\"\"\"\n",
        "    iter_n = np.random.randint(64, 97, dtype=np.int32)\n",
        "    # Clear previous gradients accumulated on parameters\n",
        "    self.optim.zero_grad()\n",
        "    # x = x.to(device)\n",
        "    for _ in range(iter_n):\n",
        "      # Forward pass of model\n",
        "      x = self.ca(x)\n",
        "    # Compute loss\n",
        "\n",
        "    loss = self.loss_f(to_rgba(x), self.target)\n",
        "    # loss = self._loss_f(x, self.target.to(device))\n",
        "    del x\n",
        "    # Compute gradients\n",
        "    loss.backward\n",
        "    # Update parameters\n",
        "    self.optim.step()\n",
        "\n",
        "    detached_loss = loss.detach().cpu().numpy()\n",
        "    del loss\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return detached_loss\n",
        "\n",
        "  def _loss_f(self, output, target):\n",
        "    return torch.square(to_rgba(output) - target).mean(dim=(-2, -3, -1))\n"
      ],
      "metadata": {
        "id": "8KBv8QUMN2Wh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Bm40gQaNHs",
        "outputId": "e333bec3-10aa-47b4-ca83-1f8bcf3c01e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 10 21:54:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    28W /  70W |  15067MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize and initiate training sequence\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "  with record_function(\"model_inference\"):\n",
        "    train = Train(CAModel().to(device), pad_target.to(device))\n",
        "    train.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "U-51JVNscnm4",
        "outputId": "74db6610-1ee7-4ea6-878d-311b630e7d67"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss log is [array(0.0613986, dtype=float32)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([72, 72, 4])) that is different to the input size (torch.Size([8, 72, 72, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " step: 1, log10(loss): -1.212loss log is [array(0.0613986, dtype=float32), array(0.0712155, dtype=float32)]\n",
            " step: 2, log10(loss): -1.147loss log is [array(0.0613986, dtype=float32), array(0.0712155, dtype=float32), array(0.09376743, dtype=float32)]\n",
            " step: 3, log10(loss): -1.028loss log is [array(0.0613986, dtype=float32), array(0.0712155, dtype=float32), array(0.09376743, dtype=float32), array(0.07103686, dtype=float32)]\n",
            " step: 4, log10(loss): -1.149"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2a5fb2003c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-d04b298ba64b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_steps)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Run through a single training step of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'loss log is {self.loss_log}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-d04b298ba64b>\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0;31m# Forward pass of model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-9e4e785450b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, fire_rate, angle, step_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y should be on device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfire_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mfire_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 14.75 GiB total capacity; 12.59 GiB already allocated; 12.81 MiB free; 13.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(prof.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=15))\n",
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_memory_usage\", row_limit=10, max_src_column_width=None, header=\"CUDA memory usage\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5PLs2QdcYMG",
        "outputId": "dc3b1706-19ff-47ed-86e6-7257056ef6ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================================================================================================================================================================================================================================================================================\n",
            "CUDA memory usage\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                            aten::zeros         0.04%       4.245ms         0.04%       4.303ms     358.583us       0.000us         0.00%       0.000us       0.000us            12                                                              [[], [], [], [], []]  \n",
            "                                            aten::empty         0.16%      18.927ms         0.19%      22.102ms       3.975us       0.000us         0.00%     277.000us       0.050us          5560                                                          [[], [], [], [], [], []]  \n",
            "                                            aten::zero_         0.00%       4.000us         0.00%       4.000us       0.333us       0.000us         0.00%       0.000us       0.000us            12                                                                             [[1]]  \n",
            "                                        model_inference         3.70%     431.823ms        99.96%       11.672s       11.672s       0.000us         0.00%        1.277s        1.277s             1                                                                                []  \n",
            "                                           aten::detach         0.00%       4.000us         0.00%      13.000us      13.000us       0.000us         0.00%       0.000us       0.000us             1                                                                 [[128, 48, 1, 1]]  \n",
            "                                                 detach         0.00%       9.000us         0.00%       9.000us       9.000us       0.000us         0.00%       0.000us       0.000us             1                                                                 [[128, 48, 1, 1]]  \n",
            "                                           aten::detach         0.00%       1.000us         0.00%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us             1                                                                           [[128]]  \n",
            "                                                 detach         0.00%       1.000us         0.00%       1.000us       1.000us       0.000us         0.00%       0.000us       0.000us             1                                                                           [[128]]  \n",
            "                                         aten::uniform_         0.00%      79.000us         0.00%      79.000us      79.000us       0.000us         0.00%       0.000us       0.000us             1                                                     [[128, 48, 1, 1], [], [], []]  \n",
            "                                         aten::uniform_         0.00%       3.000us         0.00%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us             1                                                               [[128], [], [], []]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 11.677s\n",
            "Self CUDA time total: 1.031s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "print(seed.shape)\n",
        "print(x0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ds6rzzXV79Z",
        "outputId": "84a057e9-ab1d-4c83-bbfe-d4989902078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([72, 72, 16])\n",
            "torch.Size([8, 72, 72, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0_tensor = torch.repeat_interleave(seed[None, ...], BATCH_SIZE, dim=0)\n",
        "x0_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pO2a67URt8X",
        "outputId": "a724bbeb-f874-45a2-cbc9-d7463e2e7ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 72, 72, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ca = CAModel()\n",
        "output = ca(x0)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuOJsOmmH6kk",
        "outputId": "1ee5e4b5-85d2-4ce3-8e8f-66c0e6b36a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 16, 72, 72])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "GQWbcEi2UVpI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])"
      ],
      "metadata": {
        "id": "454ZlLRVkGGa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed"
      ],
      "metadata": {
        "id": "A1WXFtqJkINu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = loss_f(seed)\n",
        "print(type(testing))\n",
        "print(testing.shape)\n",
        "print(testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB_4zm6dkIuu",
        "outputId": "0c4727e2-3db6-45f5-820a-f30832f99f4b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "()\n",
            "tf.Tensor(0.061350375, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHQJL5c5kLWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}