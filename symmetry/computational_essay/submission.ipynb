{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67c24b-0994-4538-a839-49522a412c4a",
   "metadata": {},
   "source": [
    "<h1> Symm4ml Computational Essay Final Draft</h1>\n",
    "<h3> Author: Simeon Radev</h3>\n",
    "<h3> Date: 12 May 2023</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b3b89-623e-4996-8059-4b82b5f1667a",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "\n",
    "<p> Recent work has been done on using small neural networks to model cellular automaton (CA)-like behavior, whereby such networks learn a set of \"rules\", represented as model parameters, to generate some target. \n",
    "\n",
    "Such models are already capable of generating a target pattern from a single seed pixel input, however, in their vanilla version, they cannot generate the same target in a different orientation without being explicitly retrained to do so. \n",
    "\n",
    "The goal of this project would therefore be to train a cellular automaton-like model that can learn the rules for generating a target, and can perform some simple transformations without having to retrain the model on such transformations. The motivation for this is that without such equivariance, the orientation of the model is a property of the grid space instead of the configuration of cells/pixels/nodes inside this space. Therefore this model is not fully self-organizing yet, however with such equivariant versions of the network, the orientation of the model would indeed become a property of the configuration of cells/pixels/nodes. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ec026-4945-4732-985c-e7335277d413",
   "metadata": {},
   "source": [
    "<h2>Related Work</h2>\n",
    "<p>The most direct influence for this project comes from <a href=\"https://distill.pub/2020/growing-ca/\">this Distill paper</a>. They pioneer the idea of using a small, single neural network that is applied repeatedly over a series of discrete time steps to grow the final target pattern. The relevant model parameters are then updated accordingly via backpropagation-through-time. \n",
    "\n",
    "A <a href=\"https://proceedings.neurips.cc/paper/2021/hash/af87f7cdcda223c41c3f3ef05a3aaeea-Abstract.html\">2021 NeurIPS paper</a> then extends this idea to graphical structures. There, a graph is distorted and the distortion is used as a seed input into the model. Then, via repeated applications of a single, graph-based, CA-like model, the distorted graph is made to converge to some target shape. While this model performs well for its task, it is still not equivariant and so any major transformation of the target would require that the model be retrained. </p>\n",
    "\n",
    "<p>Below we include a recreation of the experiments from the Distill blog, re-written in PyTorch from the original implementation in Tensorflow:</p>\n",
    "\n",
    "<p style=\"color:red\">TODO: Discuss more specifically their implementation and include graphic of model. Also, include briefly their follow-up with the isotropic version and how the methodology is different.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042dd3d-6d7c-49ff-bdf3-f6d5e29012e0",
   "metadata": {},
   "source": [
    "<h2>Background</h2>\n",
    "<p>The goal of this project is to make an equivariant version of either a \n",
    "two-dimensional or three-dimensional cellular automaton-like network, using \n",
    "ideas from the two main papers cited above. In the three-dimensional case \n",
    "this could obviously done with the e3nn library and standard concepts of \n",
    "equivariance in three-dimensional space covered in the class. \n",
    "\n",
    "If, however, a two-dimensional route is pursued, the equivariant model could potentially be implemented without such additional library. I am still unclear on how this would be done and would need to spend more time ideating this as well as discussing with others. </p>\n",
    "\n",
    "<p style=\"color:red\">TODOL: Include more math and discuss the group that will be used. This is the place for theoretical overview.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be872d-8673-4a79-9643-cda2afcda872",
   "metadata": {},
   "source": [
    "<h2>Methods</h2> The models that would need to be built would be similar to the ones described in the above papers, with equivariance being additionally implemented. \n",
    "\n",
    "<p>Ideally, I wanted to do this in JAX, so below is a non-working re-implementation of the same PyTorch pipeline above. For some reason, I cannot run it on GPU with PyTorch imported, so there is an accompanying notebook dedicated just for the JAX version (which should at least run). The code from that notebook is reproduced here for ease of access however.</p>\n",
    "\n",
    "<p style=\"color:red\">\n",
    "    TODO: This is the bulk. If time permits, include some individual cells of the experimentation from the playground \n",
    "    (showcasing how the library works on small examples). \n",
    "    <br>\n",
    "    Then, include the code implementations below (just for model training and class definition). Experiments will be later.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86328ea-4172-42b4-80c3-3d6467d356d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "\n",
    "# PyTorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Equivariant library\n",
    "import e2cnn\n",
    "from e2cnn import gspaces\n",
    "\n",
    "# Other dependencies \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import math\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "import time\n",
    "\n",
    "# Notebook dependencies\n",
    "from IPython.display import clear_output, Image\n",
    "\n",
    "# Import necessary functions from personal utils file\n",
    "from utils import load_emoji, imshow, get_living_mask, to_rgba, visualize_batch,\\\n",
    "    plot_loss, create_filename, save_ca_model, load_ca_model, save_loss_log, load_loss_log, simulate_model\n",
    "\n",
    "\n",
    "# For file reloading (remove before submission)\n",
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['utils'])\n",
    "from utils import load_emoji, imshow, get_living_mask, to_rgba, visualize_batch,\\\n",
    "    plot_loss, create_filename, save_ca_model, load_ca_model, save_loss_log, load_loss_log, simulate_model\n",
    "\n",
    "\n",
    "# Get access to GPU\n",
    "device_id = 0\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "print('device is {}'.format(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
